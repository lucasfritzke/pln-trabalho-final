{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cliente Agente para Recomenda√ß√£o de Filmes\n",
    "Conversa com LLama 3 (via LM Studio) usando MCP\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURA√á√ïES\n",
    "# ============================================\n",
    "\n",
    "# LM Studio API (compat√≠vel com OpenAI)\n",
    "LM_STUDIO_URL = \"http://localhost:1234/v1\"\n",
    "MODELO = \"local-model\"  # LM Studio usa esse nome gen√©rico\n",
    "\n",
    "# System prompt para o agente\n",
    "SYSTEM_PROMPT = \"\"\"Voc√™ √© um assistente especializado em recomendar filmes.\n",
    "\n",
    "Voc√™ tem acesso a um banco de dados de filmes atrav√©s das seguintes ferramentas:\n",
    "- buscar_filmes: Busca filmes por descri√ß√£o, g√™nero ou tema\n",
    "- listar_todos_filmes: Lista todos os filmes dispon√≠veis\n",
    "- estatisticas_banco: Mostra estat√≠sticas do banco\n",
    "\n",
    "IMPORTANTE:\n",
    "- Sempre use as ferramentas para buscar informa√ß√µes antes de responder\n",
    "- Seja amig√°vel e conversacional\n",
    "- Fa√ßa perguntas se n√£o entender o que o usu√°rio quer\n",
    "- Explique POR QUE voc√™ est√° recomendando cada filme\n",
    "- Use as sinopses dos filmes para contextualizar suas recomenda√ß√µes\n",
    "\n",
    "Exemplos de uso:\n",
    "- Usu√°rio: \"Quero um filme de a√ß√£o\"\n",
    "  ‚Üí Use buscar_filmes(query=\"filme de a√ß√£o\")\n",
    "\n",
    "- Usu√°rio: \"Algo engra√ßado\"\n",
    "  ‚Üí Use buscar_filmes(query=\"com√©dia engra√ßada\")\n",
    "\n",
    "- Usu√°rio: \"Quais filmes voc√™ tem?\"\n",
    "  ‚Üí Use listar_todos_filmes()\"\"\"\n",
    "\n",
    "# ============================================\n",
    "# CLIENTE AGENTE\n",
    "# ============================================\n",
    "\n",
    "class AgenteFilmes:\n",
    "    \"\"\"Cliente que conecta LLama 3 com o servidor MCP\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client_openai = OpenAI(\n",
    "            base_url=LM_STUDIO_URL,\n",
    "            api_key=\"lm-studio\"  # LM Studio n√£o valida a key\n",
    "        )\n",
    "        self.session = None\n",
    "        self.historico = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "        ]\n",
    "\n",
    "    async def inicializar_mcp(self):\n",
    "        \"\"\"Conecta ao servidor MCP\"\"\"\n",
    "        print(\"üîå Conectando ao servidor MCP...\")\n",
    "\n",
    "        server_params = StdioServerParameters(\n",
    "            command=\"python\",\n",
    "            args=[\"mcp_server.py\"],\n",
    "            env=None\n",
    "        )\n",
    "\n",
    "        stdio_transport = await stdio_client(server_params)\n",
    "        self.stdio, self.write = stdio_transport\n",
    "\n",
    "        self.session = ClientSession(self.stdio, self.write)\n",
    "        await self.session.initialize()\n",
    "\n",
    "        # Lista ferramentas dispon√≠veis\n",
    "        tools_response = await self.session.list_tools()\n",
    "        print(f\"‚úì {len(tools_response.tools)} ferramentas dispon√≠veis:\")\n",
    "        for tool in tools_response.tools:\n",
    "            print(f\"  ‚Ä¢ {tool.name}\")\n",
    "\n",
    "        return tools_response.tools\n",
    "\n",
    "    def _converter_tools_para_openai(self, tools) -> List[Dict]:\n",
    "        \"\"\"Converte tools MCP para formato OpenAI\"\"\"\n",
    "        tools_openai = []\n",
    "\n",
    "        for tool in tools:\n",
    "            tools_openai.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"parameters\": tool.inputSchema\n",
    "                }\n",
    "            })\n",
    "\n",
    "        return tools_openai\n",
    "\n",
    "    async def _executar_tool(self, tool_name: str, arguments: dict) -> str:\n",
    "        \"\"\"Executa uma tool via MCP\"\"\"\n",
    "        print(f\"\\nüîß Executando: {tool_name}\")\n",
    "        print(f\"   Argumentos: {arguments}\")\n",
    "\n",
    "        result = await self.session.call_tool(tool_name, arguments)\n",
    "\n",
    "        # Extrai texto do resultado\n",
    "        if result.content and len(result.content) > 0:\n",
    "            return result.content[0].text\n",
    "\n",
    "        return \"Nenhum resultado retornado\"\n",
    "\n",
    "    async def chat(self, mensagem_usuario: str, tools: List[Dict]) -> str:\n",
    "        \"\"\"\n",
    "        Processa uma mensagem do usu√°rio\n",
    "\n",
    "        Args:\n",
    "            mensagem_usuario: Mensagem do usu√°rio\n",
    "            tools: Lista de ferramentas dispon√≠veis\n",
    "\n",
    "        Returns:\n",
    "            Resposta do agente\n",
    "        \"\"\"\n",
    "        # Adiciona mensagem do usu√°rio ao hist√≥rico\n",
    "        self.historico.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": mensagem_usuario\n",
    "        })\n",
    "\n",
    "        max_iteracoes = 5\n",
    "        iteracao = 0\n",
    "\n",
    "        while iteracao < max_iteracoes:\n",
    "            iteracao += 1\n",
    "\n",
    "            # Chama LLama 3\n",
    "            print(f\"\\nüí≠ Pensando... (itera√ß√£o {iteracao})\")\n",
    "\n",
    "            response = self.client_openai.chat.completions.create(\n",
    "                model=MODELO,\n",
    "                messages=self.historico,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "\n",
    "            message = response.choices[0].message\n",
    "\n",
    "            # Se n√£o tem tool calls, retorna a resposta\n",
    "            if not message.tool_calls:\n",
    "                resposta_final = message.content\n",
    "                self.historico.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": resposta_final\n",
    "                })\n",
    "                return resposta_final\n",
    "\n",
    "            # Processa tool calls\n",
    "            self.historico.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": message.content,\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tc.id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tc.function.name,\n",
    "                            \"arguments\": tc.function.arguments\n",
    "                        }\n",
    "                    }\n",
    "                    for tc in message.tool_calls\n",
    "                ]\n",
    "            })\n",
    "\n",
    "            # Executa cada tool call\n",
    "            for tool_call in message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                # Executa via MCP\n",
    "                resultado = await self._executar_tool(function_name, function_args)\n",
    "\n",
    "                print(f\"‚úì Resultado recebido ({len(resultado)} caracteres)\")\n",
    "\n",
    "                # Adiciona resultado ao hist√≥rico\n",
    "                self.historico.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": resultado\n",
    "                })\n",
    "\n",
    "        return \"‚ö† N√∫mero m√°ximo de itera√ß√µes atingido\"\n",
    "\n",
    "    def limpar_historico(self):\n",
    "        \"\"\"Limpa o hist√≥rico de conversa\"\"\"\n",
    "        self.historico = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "        ]\n",
    "        print(\"üóëÔ∏è Hist√≥rico limpo\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# INTERFACE CLI\n",
    "# ============================================\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Interface de linha de comando\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"üé¨ AGENTE DE RECOMENDA√á√ÉO DE FILMES\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nInicializando...\")\n",
    "\n",
    "    # Cria agente\n",
    "    agente = AgenteFilmes()\n",
    "\n",
    "    # Conecta ao MCP\n",
    "    try:\n",
    "        tools = await agente.inicializar_mcp()\n",
    "        tools_openai = agente._converter_tools_para_openai(tools)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro ao conectar ao servidor MCP: {e}\")\n",
    "        print(\"\\nVerifique:\")\n",
    "        print(\"  1. O servidor est√° rodando? (python mcp_server.py)\")\n",
    "        print(\"  2. O Docker PostgreSQL est√° ativo?\")\n",
    "        print(\"  3. O modelo de embeddings foi baixado?\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úì Agente pronto!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüí° Dicas:\")\n",
    "    print(\"  ‚Ä¢ Digite 'sair' para encerrar\")\n",
    "    print(\"  ‚Ä¢ Digite 'limpar' para limpar hist√≥rico\")\n",
    "    print(\"  ‚Ä¢ Digite 'stats' para ver estat√≠sticas\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    # Loop de conversa\n",
    "    while True:\n",
    "        try:\n",
    "            # Input do usu√°rio\n",
    "            print(\"\\nüë§ Voc√™:\", end=\" \")\n",
    "            mensagem = input().strip()\n",
    "\n",
    "            if not mensagem:\n",
    "                continue\n",
    "\n",
    "            # Comandos especiais\n",
    "            if mensagem.lower() in ['sair', 'exit', 'quit']:\n",
    "                print(\"\\nüëã At√© logo!\")\n",
    "                break\n",
    "\n",
    "            if mensagem.lower() == 'limpar':\n",
    "                agente.limpar_historico()\n",
    "                continue\n",
    "\n",
    "            if mensagem.lower() == 'stats':\n",
    "                resultado = await agente._executar_tool(\"estatisticas_banco\", {})\n",
    "                print(f\"\\nüìä {resultado}\")\n",
    "                continue\n",
    "\n",
    "            # Processa mensagem\n",
    "            resposta = await agente.chat(mensagem, tools_openai)\n",
    "\n",
    "            # Exibe resposta\n",
    "            print(f\"\\nü§ñ Agente: {resposta}\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã At√© logo!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Erro: {e}\")\n",
    "            print(\"Continuando...\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TESTE SIMPLES\n",
    "# ============================================\n",
    "\n",
    "async def teste_simples():\n",
    "    \"\"\"Teste r√°pido do agente\"\"\"\n",
    "    print(\"üß™ Teste do agente\\n\")\n",
    "\n",
    "    agente = AgenteFilmes()\n",
    "    tools = await agente.inicializar_mcp()\n",
    "    tools_openai = agente._converter_tools_para_openai(tools)\n",
    "\n",
    "    # Testa algumas queries\n",
    "    queries = [\n",
    "        \"Quero um filme de a√ß√£o emocionante\",\n",
    "        \"Algo mais tranquilo, uma com√©dia\",\n",
    "        \"Quais filmes voc√™ tem sobre espionagem?\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üë§ {query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        resposta = await agente.chat(query, tools_openai)\n",
    "        print(f\"\\nü§ñ {resposta}\\n\")\n",
    "\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == \"teste\":\n",
    "        asyncio.run(teste_simples())\n",
    "    else:\n",
    "        asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
